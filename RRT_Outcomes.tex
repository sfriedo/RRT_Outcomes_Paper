
%% bare_conf_compsoc.tex
%% V1.4b
%% 2015/08/26
%% by Michael Shell
%% See:
%% http://www.michaelshell.org/
%% for current contact information.
%%
%% This is a skeleton file demonstrating the use of IEEEtran.cls
%% (requires IEEEtran.cls version 1.8b or later) with an IEEE Computer
%% Society conference paper.
%%
%% Support sites:
%% http://www.michaelshell.org/tex/ieeetran/
%% http://www.ctan.org/pkg/ieeetran
%% and
%% http://www.ieee.org/

%%*************************************************************************
%% Legal Notice:
%% This code is offered as-is without any warranty either expressed or
%% implied; without even the implied warranty of MERCHANTABILITY or
%% FITNESS FOR A PARTICULAR PURPOSE! 
%% User assumes all risk.
%% In no event shall the IEEE or any contributor to this code be liable for
%% any damages or losses, including, but not limited to, incidental,
%% consequential, or any other damages, resulting from the use or misuse
%% of any information contained here.
%%
%% All comments are the opinions of their respective authors and are not
%% necessarily endorsed by the IEEE.
%%
%% This work is distributed under the LaTeX Project Public License (LPPL)
%% ( http://www.latex-project.org/ ) version 1.3, and may be freely used,
%% distributed and modified. A copy of the LPPL, version 1.3, is included
%% in the base LaTeX documentation of all distributions of LaTeX released
%% 2003/12/01 or later.
%% Retain all contribution notices and credits.
%% ** Modified files should be clearly indicated as such, including  **
%% ** renaming them and changing author support contact information. **
%%*************************************************************************
\documentclass[conference,comsoc]{IEEEtran}

% *** CITATION PACKAGES ***
%
\ifCLASSOPTIONcompsoc
  % IEEE Computer Society needs nocompress option
  % requires cite.sty v4.0 or later (November 2003)
  \usepackage[nocompress]{cite}
\else
  % normal IEEE
  \usepackage{cite}
\fi

\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{amsmath}
\usepackage[margin=1in]{geometry}
\usepackage{array}
\newcolumntype{C}[1]{>{\centering\arraybackslash}p{#1}}
\usepackage{longtable}
\graphicspath{ {figures/} }
\usepackage[acronym,nomain]{glossaries}

\newacronym{cdss}{CDSS}{Clinical Decision Support System}
\newacronym{rrt}{RRT}{Renal Replacement Therapy}
\newacronym{icu}{ICU}{Intensive Care Unit}
\newacronym{brl}{BRL}{Bayesian Rule Lists}
\newacronym{dnn}{DNN}{Deep Neural Network}
\newacronym{aki}{AKI}{Acute Kidney Injury}
\newacronym{svm}{SVM}{Support Vector Machine}
\newacronym{gfr}{GFR}{Glomerular Filtration Rate}


\begin{document}
\title{Prediction of Patient Outcomes after \\Renal Replacement Therapy in the Intensive Care Unit }


% author names and affiliations
% use a multiple column layout for up to three different
% affiliations
\author{
\IEEEauthorblockN{Siegfried Horschig}
\IEEEauthorblockA{Hasso Plattner Institute (HPI) \\
Enterprise Platform and Integration Concepts \\
Potsdam, Germany\\
Email: siegfried.horschig@student.hpi.de}
}
\maketitle

\begin{abstract}
In order to compensate impairments of the renal system in the human body, artificial methods in the form of \gls{rrt}, called dialysis, have to be introduced.
Many parameters of the dialysis can be adjusted and the outcome of the procedure may change with different patient characteristics. 
In this paper, we introduce a clinical decision support system to predict the effect of a given dialysis on a patient while in the \gls{icu}. \\
For this purpose, we employ two kinds of machine learning models: \gls{brl} and \gls{dnn}. Although the \gls{dnn} may provide better accuracy, its decision making is not easily interpretable for humans. For this reason, we use mimic learning as a method to make the \gls{dnn} interpretable. \\
Results show us that the \gls{dnn} outperforms our \gls{brl} classifier as expected, but by a rather small margin.
For the mimic learning process, we used a Bayesian Ridge Regression model.
Even though the regression model performs worse when training as a mimic model as opposed to directly on the data, it provides some insight into the inner workings of the \gls{dnn}.
\end{abstract}


\section{Introduction}
The renal system in the human body has the purpose to eliminate wastes from the body and control levels of certain substances in the blood. 
If this system is impaired, for example due to \gls{aki}, artificial methods in the form of \gls{rrt} have to be introduced, more commonly known under the term of dialysis. \\
There are different options for dialysis available.
One example is the hemodialysis, where the patient's blood is pumped through a dialyzer, inside of which is a liquid called dialysate.
This liquid's composition determines which substances should be filtered out of the blood.
The dialyzer separates the blood and the dialysate though a partially permeable membrane, allowing for the filtering of the blood through osmosis.
Another example for the dialysis is the peritoneal dialysis, which uses the peritoneal cavity inside the patient as a container for the dialysate. \\

The dialysis’ outcomes are highly dependent on both the patient’s characteristics and the parameters as well as the type of the dialysis. 
So, usually, patients undergoing the peritoneal dialysis experience lesser health issues related to the dialysis than those undergoing hemodialysis, as there is less pressure on the circulatory system \cite{Fenton1997}.
On the other hand, the hemodialysis is more efficient in such a way that it needs less time for the same amount of filtration. \\
Especially the hemodialysis is a costly process which needs specialized equipment and therefore has many parameters to be tuned. 
These include, but are not limited to the duration of the process, the filtration rate and flow rates of the blood and dialysate.
There is no consensus about the optimal duration for a dialysis procedure.
Studies exist proposing both longer durations \cite{jungers2001longer} as well as shorter procedures \cite{ronco1988technical}.
It stands to reason that a \gls{cdss} is needed in order to predict optimal parameters based on patients' characteristics. \\

Aside from usual criteria like accuracy or recall, when employing a machine learning model in the medical context one especially important factor is the interpretability of the model \cite{Katuwal2016}.
This is due to the fact that the doctors want to make decisions based on those predictions and take full responsibility for the consequences, so they have to validate the decision making process.
Oftentimes, models just show correlations between various parameters, and those correlations have to be manually checked for causal relations.
Additionally, the European Union introduced regulations (taking effect 2018) that give consumers in any sector a "right to explanation" \cite{goodman2016european}.
Essentially, this means that in any decision making process that is done by machines, be it a credit application or a diagnosis, the individual has the right to access meaningful information about the logic involved. \\

This way, we can roughly separate machine learning algorithms in two categories: interpretable and non-interpretable. 
One example for interpretable models are \gls{brl} \cite{Letham2015}.
By presenting itself as \emph{if...then...else} lists, it is easy for humans to comprehend both the decision making and the individual influence of each parameter on the outcome. \\
\gls{dnn} on the other hand are more accurate, but non-interpretable.
This is because the weights of the nodes in the hidden layers is everything they expose to the outside.
Due to the fact that different loss and activation functions take effect when updating those weights, the abstraction to the original input data is just too large for a human to grasp. \\
At this point, we have a tradeoff between interpretability and accuracy.
In order to overcome this tradeoff, we employ a strategy called mimic learning \cite{Che2016}.
By training an interpretable model on the predictions of the more accurate, non-interpretable model, we gain insight into its decision process and can therefore make the non-interpretable model interpretable. \\

The main purpose of this paper is to develop a \gls{cdss} to determine patient-specific outcomes after \gls{rrt} in the \gls{icu}.
We evaluate the performance and interpretability of two different models, \gls{brl} as the interpretable one and \gls{dnn} as the non-interpretable one.
Afterwards, we employ mimic learning to overcome the tradeoff between accuracy and interpretability and give some insight into the decision making process of the \gls{dnn}.
We then ask an expert in the field of renal medicine for further evaluation and validation of the models. \\

After evaluating related work in section \ref{sec:related}, we present the tools, data and models used in section \ref{sec:methods}.
Thereafter, we present the results in section \ref{sec:results} and discuss them in section \ref{sec:discussion}.

\section{Related Work}
\label{sec:related}
In the field of prediction concerning the renal system, a significant amount of work has already been done.
For example, Schwenger et al. researched the mortality of patients undergoing dialysis with different procedures, thus making patient mortality a fitting target for prediction by our model \cite{Schwenger2012}.
Likewise, Ricci et al. researched dialysis duration and showed impact of blood values, making them suitable features to train the model upon \cite{Ricci2006}. \\
When it comes to model selection, Baby et al. found a bayes algorithm suitable \cite{Baby2015}, while Greco et al. proposed decision trees \cite{Greco2010}.
The issue with those models is that they lack accuracy when compared to more advanced models.
Vijayarani et al. and Sinha et al. used \gls{svm} for the prediction in the renal context and achieved satisfying results, but lack interpretablity \cite{Vijayarani2015} \cite{Sinha2015}.
In an equal manner, Lakshmi et al. compared the three models regression, random forest and artificial neural networks and proposed the latter for better performance and accuracy, while still lacking interpretability \cite{Lakshmi2014}. \\
Lipton et al. discussed the term \emph{interpretability} in the context of machine learning \cite{Lipton2016}. 
Particular focus was on the definition of the decision boundaries as well as influence of specific features, which is important for our evaluation.
Katuwal et al. worked on achieving interpretability of machine learning models in precision medicine and used the locally-interpretable model- agnostic explanations (LIME) technique, achieving accuracies of 80\% \cite{Katuwal2016}.
Ultimately, we decided on using the mimic learning technique as proposed by Che et al. for usage in the context of patients in the \gls{icu} \cite{Che2016}.
While Che et al. used Gradient Boosting Trees as mimic learning model, we wanted to employ a different model and compare the results, especially when transferred into the renal context.

In the context of this work, we try to unify both the prediction of patient outcomes in the renal context as well as the interpretability of the models used.
We compare the results of mimic learning as described by Che et al. with the results of an interpretable classifier, \gls{brl} as proposed by Letham et al \cite{Che2016} \cite{Letham2015}.

\section{Methods}
\label{sec:methods}
In this section, we will present our methods and data for predicting patient outcomes after \gls{rrt} in the \gls{icu}.
We start by naming the tools used to create the models and the data those models operate upon.
Afterwards, we will explain the models used as well as the interpretability approach.
This section concludes with the introduction of our performance metrics applied to evaluate the models.

\subsection{Tools}
For quick prototyping, we used \emph{RapidMiner} \cite{RapidMiner}, allowing us to prepare data, develop and cross-validate first models. 
For the final models, we implemented them with the \emph{scikit-learn} library \cite{SKLearn} in Python. \\
The Data we used was provided by the \emph{MIMICIII} dataset \cite{Johnson2016} stored in a \emph{HANA} database \cite{Farber2012}.


\subsection{Data}
The \emph{MIMICIII} dataset contains hospital admission data for patient collected over an eleven-year period in a Boston hospital. 
As seen in figure \ref{fig:cohort}, out of the approximately 46,000 patients present in the dataset, we extracted 925 relevant patients for us, totaling to approximately 3,000 dialysis procedures we can train our models upon.

\begin{figure}[h]
	\includegraphics[width=0.5\textwidth]{cohort.jpg}
	\label{fig:cohort}
	\caption{Cohort selection of the dialysis procedures based on the patients.}
\end{figure}

For each procedure, we have about 80 features defining it.
In cooperation with an expert from the \emph{Nierenzentrum Heidelberg}, we conducted interviews in order to curate a list of suitable features.
Those include patient demographics such as age or BMI, dialysis parameters such as the duration of the procedure, comorbidities as well as lab values. 
Additionally, we include patient vitals and measurements on how "well" the patient is doing such as 90-day mortality, the number of days he/she spent without mechanical ventilation and in the ICU in general.
The full list of input and output features can be seen in the appendices \ref{app:input} and \ref{app:output}.

\subsubsection{Missing Data}
Due to the manually curated nature of the \emph{MIMICIII} dataset, aside from the inconsistencies within, a significant amount of data is missing. 
For example, the columns showing Creatinine and \gls{gfr} values before and after the procedure are missing in 20\% of samples.
As the scikit-learn models need a complete dataset for training, we decided to impute the missing values.


\subsection{Models}
In order to compare performance of both interpretable and non-interpretable models, we trained one model for each category.
Thus, the important factors are the representation of the model as well as accuracy, which is especially in a medical context of utmost importance.
In the following section, we describe the models and strategies used as well as the parameters chosen for training.

\subsubsection{Interpretable - Bayesian Rule Lists}
For the interpretable model, we chose the existing Python 2 implementation of \gls{brl} as described by Letham et al. \cite{Letham2015}.
They position themselves as a direct competitor to decision tree approaches, as they have a high accuracy for classification while still being easy to read for humans. \\
This algorithm tries to find \emph{if...then...else} statements over a dataset with the important criteria of them being sparse for better human readability. 
It build Bayesian association rules, consisting of an antecedent $a$ and a consequent $b$.
The consequent has a multinomial distribution over all the predicted labels $y$, so that the rules look like this:
\begin{equation}
a \rightarrow y \sim Multinomial(\theta)
\end{equation}
These rule are generated by mining antecedents from the data and afterwards computing the posterior consequent distribution over the antecedent lists. \\
\gls{brl} have the advantage of being very easy to interpret due to their sparsity while retaining accuracy in classification.
However, there are algorithms providing a higher accuracy, which also have the capability of more elaborate parameter tuning.
Additionally, the current implementation of \gls{brl} has the shortcoming of a very long runtime and only being able to classify binary targets. 
Thus, we have to adjust the target features accordingly.
\paragraph{Parameters}
The sole adjustable parameter in the used implementation is the maximum number of iterations. 
Multiple adjustments to this parameter - including changes by factor 10 - did not result in a significant change, neither for the runtime nor for the accuracy. 
For the evaluation, we chose a value of 50,000 maximum iterations.

\subsubsection{Non-Interpretable - Deep Neural Network}
As non-interpretable model, we chose the powerful and widely used \gls{dnn}. 
Specifically, the scikit-learn implementation Multi-Layer Perceptron (MLP), which offers implementations for both regression and classification tasks.
Just as other implementations, this network consists of multiple layers of so-called "neurons": one input layer with as many neurons as there are inputs, one output layer with the size of the number of target features and hidden layers varying in size and quantity. 
The weights of each neuron is updated after each iteration of training, optimizing the log-loss function. 
One can represent the neural network as a mathematical function $f(x)$, with $g_i (x)$ being other functions representing the dependencies between functions and $w_i$ being the weights of a node. 
\begin{equation}
f(x) = K(\sum _i w_i g_i (x))
\end{equation}
Here, $K$ is the activation function, such as the rectifier function. \\
\gls{dnn} are a widely used form of machine learning due to their versatility and high accuracy.
They provide a wealth of parameters to tune, but finding the right ones for a specific use case can prove cumbersome.
Furthermore, the decision making of such a neural network is not comprehensible to a human and thus provides nearly no interpretability.
\paragraph{Parameters}
The amount of parameters to be adjusted when using neural networks is very high.
Doing a grid search over some of the parameters, we found the default ones from the library to perform the best.\\
This means the learning rate - determining the speed and accuracy of convergence - is set to 0.001. 
The activation function, determining the output of the neurons in the hidden layer, is the rectifier linear unit "relu". 
The network consists of one hidden layer with 100 neurons. 
The maximum number of iterations before convergence is set to 200.

\subsubsection{Interpretablity Approach - Mimic Learning}
The large amount of neurons in the \gls{dnn} and the many parameters influencing their weights and output make it very difficult - if not impossible - for a human to understand the influence of each feature on the training. \\
That is why we wanted to give some insight into the workings of the \gls{dnn} by applying a method called \emph{mimic learning}. 
Building upon the approach of Che et al. \cite{Che2016}, we train an interpretable model - the so-called "mimic model" - on the outputs of the non-interpretable model.
The mimic model takes the same input features as the non-interpretable model.
For classification tasks, the output of the non-interpretable model are called "soft scores", because as they are probabilites, they are continuous variables, coming close to the actual target features.
In theory, the training of the mimic model on the soft scores allows to create a much smaller, thus understandable, faster but still equally accurate model.
Using the principle Che et al. called "knowledge distillation", it is even possible for the mimic model to perform better than the non-interpretable model.
This means, that certain noise in the training data, which could have a bad influence on training performance of the interpretable model, gets filtered out by the non-interpretable model. \\
In our case, the \gls{dnn} is the non-interpretable model.
For the mimic model, we need a model which is able to predict continuous scores.
We decided on Bayesian Ridge Regression.
\paragraph{Bayesian Ridge Regression}
The Bayesian Ridge Regression, like common linear regression, tries to find coefficients for each input feature so that they map to the target feature, minimizing loss.
In addition to common linear regression, it includes regularization parameters to control the growth of the coefficients.
Therefore, this model is less prone to overfitting while still being as fast as linear regression. \\
Regression in general has the advantage of being very fast concerning training time and interpretable, as you can see the coefficients for each feature.
However, due to the simplicity of regression models, they are usually lacking accuracy when compared to more elaborate algorithms. \\
Very few parameters can be adjusted for this algorithm and for our experiments, we stuck with the default ones.
This means that all regularization parameters are set to $10^{-6}$ and the number of iterations before convergence is set to 300.


\subsection{Performance Metrics}
In order to compare the models' performance to each other, we have to specify performance metrics, in this case for binary classification.
We use very common criteria like \emph{Precision} or \emph{Recall} which were evaluated by Powers \cite{powers2011evaluation}.
All of them are working with the terms of true and false positives and negatives.
The terms \emph{positives} and \emph{negatives} refer to the prediction of the model, while the terms of \emph{true} and \emph{false} refer to the fact if the prediction of the model was correct.
Additionally, all targets that are true are \emph{relevant} elements. \\
\textbf{Sensitivity / Recall} specifies the number of relevant items that have been selected.
This means the number of true positives divided by the number of all true targets. \\
\textbf{Precision} specifies the number of relevant instances in the result set.
This means, out of all as positively classified targets, how many have actually been positive. \\
The \textbf{Receiver Operating Characteristics curve} (ROC) plots the true positive rate against the false positive rate at various thresholds.
The important measure for this plot is the \textbf{Area Under the Curve} (AUC), a value ranging from zero to one, with an AUC of 0.5 describing a random classifier.
Higher values indicate better classification performance. \\
\textbf{Specificity} specifies the number of correctly classified negative instances. \\
The \textbf{Diagnostic Odds Ratio} (DOR) as proposed by Glas et al.\cite{glas2003diagnostic} is defined as the ratio of the odds of the prediction being positive if the target is positive against the odds that the prediction is positive if the target is negative.
It range from zero to infinity, with a DOR of 1 meaning that the prediction is equally likely to give a positive prediction no matter the true status.
A higher value indicates a better prediction.


\section{Results}
\label{sec:results}
In the following section, we want to compare the performance of our interpretable model, the BRL, and our non-interpretable model, the DNN.
Although there are continuous values for our target variables in the dataset, we had to transform them into a binary format in order for the BRL classifier to work.
This is why the target variable for this sample is mortality within 90 days of the procedure.

\begin{figure}[h]
	\includegraphics[width=0.5\textwidth]{class_DIED_90DAYS.jpg}
	\label{fig:mortalityCLASS}
	\caption{Performance comparison of the classifiers when predicting 90-day mortality.}
\end{figure}

Figure \ref{fig:mortalityCLASS} shows general performance of the classifiers.
We can see that, as expected, the DNN outperforms the BRL classifier in every performance criteria.
The difference is about ten percent for every performance measure.

\begin{figure}[h]
	\includegraphics[width=0.5\textwidth]{brl_DIED_90DAYS.jpg}
	\label{fig:mortalityBRL}
	\caption{Excerpt of the rules from the BRL classifier when prediction 90-day mortality.}
\end{figure}

Due to the interpretable nature of the BRL, we can look at the importance of single features.
Figure \ref{fig:mortalityBRL} shows the influence of some features and their values on the prediction of 90-day mortality.
For example, we can see that a lower \emph{Elixhauser-van Walraven} score - a score combining several comorbidities - along with a lower \emph{Glomerular Filtration Rate} two days before the procedure leads to a lower possibility of death within 90 days. \\

\begin{figure}[h]
	\includegraphics[width=0.5\textwidth]{ROC_DIED_90DAYS.png}
	\label{fig:mortalityROC}
	\caption{ROC curve comparing the classifiers for prediction of 90-day mortality.}
\end{figure}

If we want to see how the DNN actually makes its decisions, we have to apply the mimic learning strategy.
First, we have to evaluate if the performance of the mimic model is reasonably good when only being trained on the outputs of the DNN.
Figure \ref{fig:mortalityROC} presents the performance of the mimic model - our Bayesian Ridge Regression - relative to the other classifiers.
We can see that, while the regression is still worse than the DNN, it performs better than the BRL, if only by a small margin. \\

\begin{figure}[h]
	\includegraphics[width=0.5\textwidth]{coef_DIED_90DAYS.png}
	\label{fig:mortalityCOEF}
	\caption{Coefficients of the most important features for the Bayesian Ridge Regression trained as mimic model when predicting for a true outcome of 90-day mortality.}
\end{figure}

If we now look into the most important coefficients of the regression in figure \ref{fig:mortalityCOEF}, we can see the influence of single features on a positive prediction of 90-day mortality.
So, for example, the higher the rightmost feature, the age of the patient, the higher is the probability of the patient to die within 90 days.
On the other hand side, the higher the leftmost feature, the potassium value in the blood of the patient, the less likely the patient is to die within 90 days.

\section{Discussion}
\label{sec:discussion}
The classification results of the models can be improved.
While providing a sufficiently good performance for researching the interpretability, their confidence has to be higher for the practical use in the medical context. \\
Looking at the influence of single features, the results are mixed.
While some of them make sense intuitively, like a higher age correlating with a higher chance of mortality, some just appear to be coincidental correlations.
For example, there is most probably not a linear correlation between certain blood values and the mortality, as either too low or too large values can be influencing the patient's health negatively.
In the case of potassium, values between 3.5 and 5.5 \textmu g/l would be fine values, but higher or lower values can lead to heart arrhythmia. \\
The same observation holds true for the output of the BRL.
While obesity and a longer stay in the hospital are most likely indeed factors for a higher mortality, other associations with the lactate value in the blood may be random coincidence.
Especially because higher lactate values usually lead to other complications, so the upper bound of "infinity" is very rough. \\
In order to refine and validate those assumptions, it is necessary to go further with the data analysis.
Finding actual upper and lower bounds in the dataset can provide some insight to the actual values the model considers when making predictions. \\

By training the regression as a mimic model, we can make assumptions on how the DNN \emph{may} make its decisions.
There still is a gap between the performance of the regression model and the DNN, which makes it difficult to say how close those coefficients are to the actual influence of features in the DNN.
The mimic model performs worse when being trained on the outputs of the DNN as opposed to being trained on the real targets, because it most probably also learns the errors of the DNN.
This can be a resolvable issue by improving the performance of the DNN through further parameter tuning and data preparation.


\section{Conclusion}
In this paper, we compared the performance of different models when being used in the prediction in the renal context.
An important part is the interpretability of said models to validate the decision making.
We used a mimic learning approach to make a \gls{dnn} interpretable and compared this output to that of the interpretable model, the \gls{brl}.
Preliminary results for prediction of 90-day mortality enable the exploration of interpretability, showing the influence of single features.
While some of the features' influence can intuitively be classified as correct, others' influence needs further data examination to prove or disprove. \\

Future work includes more elaborate use of the data. 
This means the inclusion of more features, more elaborate imputation and collection of information about the patients. \\
Additionally, more target features can be added to the existing experiments. 
The binary classification limitation of the current implementation of BRL can be overcome by using a more advanced algorithm proposed by Yang \cite{Yang2016}.
When a higher precision is achieved, interpretable models can be used as a Clinical Decision Support System, allowing the doctors to validate the decisions and giving patients insight into their treatment.

\bibliographystyle{IEEEtran}
\bibliography{references}

\onecolumn

\appendices
\section{Input Features}
\label{app:input}


\begin{longtable}[c]{C{0.2\textwidth} | C{0.2\textwidth} | C{0.4\textwidth} | C{0.2\textwidth}}

\textbf{Attribute Group} & \textbf{Attribute} & \textbf{Remarks} & \textbf{Data Type} \\
\midrule
Demographics & Gender & & Nominal \\
Demographics & Ethnicity & & Nominal \\
Demographics & Age & & Integer \\
Demographics & Height & & Integer \\
Demographics & Weight & & Integer \\
Demographics & BMI & & Integer \\
Comorbidities & Aids & & Boolean \\
Comorbidities & Acute Kidney Injury & e.g. 'NO AKI', ''STAGE1', ect. & Nominal \\
Comorbidities & Coagulopathy & & Boolean \\
Comorbidities & Congestive Heart Failure & & Boolean \\
Comorbidities & Blood Loss Anemia & & Boolean \\
Comorbidities & Iron Deficiency Anemia & & Boolean \\
Comorbidities & Depression & & Boolean \\
Comorbidities & Diabetes Complicated & & Boolean \\
Comorbidities & Diabetes Uncomplicated & & Boolean \\
Comorbidities & Fluid Electrolyte Imbalance     & & Boolean \\
Comorbidities & Hypertension & & Boolean \\
Comorbidities & Hypothyroidism & & Boolean \\
Comorbidities & Liver Disease & & Boolean \\
Comorbidities & Lymphoma & & Boolean \\
Comorbidities & Metastatic Cancer & & Boolean \\
Comorbidities & Solid Tumor & & Boolean \\
Comorbidities & Obesity & & Boolean \\
Comorbidities & Paralysis & & Boolean \\
Comorbidities & Other Neurological & & Boolean \\
Comorbidities & Peptic Ulcer & & Boolean \\
Comorbidities & Peripheral Vascular Disease & & Boolean \\
Comorbidities & Psychoses & & Boolean \\
Comorbidities & Pulmonary Vascular Disease & & Boolean \\
Comorbidities & Renal Failure & & Boolean \\
Comorbidities & Arthritis & & Boolean \\
Comorbidities & Valvular Disease & & Boolean \\
Comorbidities & Weight Loss & & Boolean \\
ICU Aggregate Measures/Scores & Elixhauser van Walraven & & Real Number \\
ICU Aggregate Measures/Scores & SOFA score total & & Real Number \\
ICU Aggregate Measures/Scores & SOFA score renal & & Real Number \\
ICU Aggregate Measures/Scores & SAPS score total & & Real Number \\
ICU Aggregate Measures/Scores & OASIS score & & Real Number \\
Lab Values & Albumin & Averaged over values measured before procedure started  & Real Number \\
Lab Values & Anion & Gap   Averaged over values measured before procedure started  & Real Number \\
Lab Values & Bands &   Averaged over values measured before procedure started  & Real Number \\
Lab Values & Bicarbonate & Averaged over values measured before procedure started  & Real Number \\
Lab Values & Bilirubin &   Averaged over values measured before procedure started  & Real Number \\
Lab Values & BUN & Averaged over values measured before procedure started  & Real Number \\
Lab Values & Glucose & Averaged over values measured before procedure started  & Real Number \\
Lab Values & Hematocrit &  Averaged over values measured before procedure started  & Real Number \\
Lab Values & Hemoglobin &  Averaged over values measured before procedure started  & Real Number \\
Lab Values & INR & Averaged over values measured before procedure started  & Real Number \\
Lab Values & PT &  Averaged over values measured before procedure started  & Real Number \\
Lab Values & PTT (Partial Thromboplastin Time) & Averaged over values measured before procedure started  & Real Number \\
Lab Values & Lactate & Averaged over values measured before procedure started  & Real Number \\
Lab Values & Platelet &    Averaged over values measured before procedure started  & Real Number \\
Lab Values & Potassium &   Averaged over values measured before procedure started  & Real Number \\
Lab Values & Sodium &  Averaged over values measured before procedure started  & Real Number \\
Lab Values & WBC & Averaged over values measured before procedure started  & Real Number \\
Event Procedure Info & Dosage & Length of Dialysis Procedure & Integer \\
Lab Values & GFR\textunderscore 24\textunderscore B & Glomerular Filtration Rate 24 Hours before the procedure & Real number \\
Lab Values & GFR\textunderscore 48\textunderscore B & Glomerular Filtration Rate 48 Hours before the procedure & Real number \\
Lab Values & GFR\textunderscore 72\textunderscore B & Glomerular Filtration Rate 72 Hours before the procedure & Real number \\
Lab Values & GFR\textunderscore 24\textunderscore A & Glomerular Filtration Rate 24 Hours after the procedure & Real number \\
Lab Values & GFR\textunderscore 48\textunderscore A & Glomerular Filtration Rate 48 Hours after the procedure & Real number \\
Lab Values & GFR\textunderscore 72\textunderscore A & Glomerular Filtration Rate 72 Hours after the procedure & Real number \\
Lab Values & Creatinine\textunderscore 24\textunderscore B & Creatinine 24 Hours before the procedure & Real number \\
Lab Values & Creatinine\textunderscore 48\textunderscore B & Creatinine 48 Hours before the procedure & Real number \\
Lab Values & Creatinine\textunderscore 72\textunderscore B & Creatinine 72 Hours before the procedure & Real number \\
Lab Values & Creatinine\textunderscore 24\textunderscore A & Creatinine 24 Hours after the procedure & Real number \\
Lab Values & Creatinine\textunderscore 48\textunderscore A & Creatinine 48 Hours after the procedure & Real number \\
Lab Values & Creatinine\textunderscore 72\textunderscore A & Creatinine 72 Hours after the procedure & Real number \\
Vitals & Heart Rate & Earliest value at the beginning of the procedure & Integer \\
Vitals & Systolic Blood Pressure & Earliest value at the beginning of the procedure & Integer \\
Vitals & Diastolic Blood Pressure & Earliest value at the beginning of the procedure & Integer \\
Vitals & Mean Blood Pressure & Earliest value at the beginning of the procedure & Integer \\
Vitals & Respiration Rate & Earliest value at the beginning of the procedure & Integer \\
Vitals & Temperature & Temperature in \textdegree C, Earliest value at the beginning of the procedure & Integer \\
Vitals & SPO2 & Blood Oxygen Level, Earliest value at the beginning of the procedure & Integer \\
\end{longtable}

\section{Model Output}
\label{app:output}


\begin{longtable}[c]{C{0.5\textwidth} | C{0.5\textwidth}}

\textbf{Attribute} & \textbf{Data Type} \\
\midrule
\gls{icu} Length of Stay \textless 7 Days & Boolean \\
Mechanical Ventilation Free \textless 7 Days & Boolean \\ 
90-Day Mortality & Boolean \\
\gls{icu} Length of Stay & Numeral \\
Mechanical Ventilation Free & Numeral \\
\end{longtable}

\end{document}


